################################################################################
# MIT License
#
# Copyright (c) 2025 University of Amsterdam
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to conditions.
#
# Author: Deep Learning Course (UvA) | Fall 2025
# Date Created: 2025-11-08
################################################################################
"""
Script to compare PyTorch MLP performance with and without batch normalization.
Reads JSON files generated by train_mlp_pytorch.py and displays comparison table.
"""

import json
import os
import argparse
import matplotlib.pyplot as plt


def read_metrics_json(json_path):
    """
    Reads training metrics from a JSON file.
    
    Args:
        json_path: Path to the JSON file
        
    Returns:
        Dictionary containing epochs, train_accuracy, val_accuracy, test_accuracy
    """
    with open(json_path, 'r') as jsonfile:
        metrics = json.load(jsonfile)
    return metrics


def print_comparison_table(metrics_no_bn, metrics_with_bn):
    """
    Prints a formatted comparison table of metrics.
    
    Args:
        metrics_no_bn: Dictionary with metrics without batch norm
        metrics_with_bn: Dictionary with metrics with batch norm
    """
    epochs = metrics_no_bn['epochs']
    train_no_bn = metrics_no_bn['train_accuracy']
    val_no_bn = metrics_no_bn['val_accuracy']
    test_no_bn = metrics_no_bn['test_accuracy']
    
    train_with_bn = metrics_with_bn['train_accuracy']
    val_with_bn = metrics_with_bn['val_accuracy']
    test_with_bn = metrics_with_bn['test_accuracy']
    
    print("\n" + "="*110)
    print("BATCH NORMALIZATION COMPARISON - PyTorch MLP")
    print("="*110)
    print(f"\n{'Epoch':<8} {'Without Batch Norm':<45} {'With Batch Norm':<45}")
    print(f"{'':8} {'Train Acc':<12} {'Val Acc':<15} {'Val delta':>15} {'Train Acc':<12} {'Val Acc':<15} {'Val delta':>15}")
    print("-"*110)
    
    for i, epoch in enumerate(epochs):
        val_diff = val_with_bn[i] - val_no_bn[i]
        
        # Mark best validation accuracy with *
        val_no_bn_str = f"{val_no_bn[i]:.4f}"
        val_with_bn_str = f"{val_with_bn[i]:.4f}"
        
        if val_no_bn[i] == max(val_no_bn):
            val_no_bn_str += "*"
        if val_with_bn[i] == max(val_with_bn):
            val_with_bn_str += "*"
        
        print(f"{epoch:<8} {train_no_bn[i]:>10.4f}   {val_no_bn_str:<15} "
              f"{'--':>15} {train_with_bn[i]:>10.4f}   {val_with_bn_str:<15} "
              f"{val_diff:>+14.4f}")
    
    print("-"*110)
    print(f"\n{'Best Model Test Accuracy (based on best validation):':<60}")
    print(f"  - Without Batch Norm: {test_no_bn:.4f}")
    print(f"  - With Batch Norm:    {test_with_bn:.4f}")
    print(f"  - Improvement:        {test_with_bn - test_no_bn:+.4f}")
    print("\n" + "="*110 + "\n")


def plot_comparison(metrics_no_bn, metrics_with_bn, save_path='plots/batch_norm_comparison.png'):
    """
    Creates a comparison plot of training and validation accuracies.
    
    Args:
        metrics_no_bn: Dictionary with metrics without batch norm
        metrics_with_bn: Dictionary with metrics with batch norm
        save_path: Path to save the comparison plot
    """
    epochs = metrics_no_bn['epochs']
    train_no_bn = metrics_no_bn['train_accuracy']
    val_no_bn = metrics_no_bn['val_accuracy']
    
    train_with_bn = metrics_with_bn['train_accuracy']
    val_with_bn = metrics_with_bn['val_accuracy']
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Training accuracy comparison
    axes[0].plot(epochs, train_no_bn, 'b-o', label='Without Batch Norm', linewidth=2, markersize=6)
    axes[0].plot(epochs, train_with_bn, 'r-s', label='With Batch Norm', linewidth=2, markersize=6)
    axes[0].set_xlabel('Epoch', fontsize=12)
    axes[0].set_ylabel('Training Accuracy', fontsize=12)
    axes[0].set_title('Training Accuracy Comparison', fontsize=14, fontweight='bold')
    axes[0].legend(fontsize=10)
    axes[0].grid(True, alpha=0.3)
    
    # Validation accuracy comparison
    axes[1].plot(epochs, val_no_bn, 'b-o', label='Without Batch Norm', linewidth=2, markersize=6)
    axes[1].plot(epochs, val_with_bn, 'r-s', label='With Batch Norm', linewidth=2, markersize=6)
    
    # Mark best validation accuracy with a star
    best_val_idx_no_bn = val_no_bn.index(max(val_no_bn))
    best_val_idx_with_bn = val_with_bn.index(max(val_with_bn))
    
    axes[1].plot(epochs[best_val_idx_no_bn], val_no_bn[best_val_idx_no_bn], 
                marker='*', markersize=20, color='gold', markeredgecolor='blue', 
                markeredgewidth=2, zorder=5, label=f'Best (No BN): {val_no_bn[best_val_idx_no_bn]:.4f}')
    axes[1].plot(epochs[best_val_idx_with_bn], val_with_bn[best_val_idx_with_bn], 
                marker='*', markersize=20, color='gold', markeredgecolor='red', 
                markeredgewidth=2, zorder=5, label=f'Best (With BN): {val_with_bn[best_val_idx_with_bn]:.4f}')
    
    axes[1].set_xlabel('Epoch', fontsize=12)
    axes[1].set_ylabel('Validation Accuracy', fontsize=12)
    axes[1].set_title('Validation Accuracy Comparison', fontsize=14, fontweight='bold')
    axes[1].legend(fontsize=10)
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"Comparison plot saved to: {save_path}")
    plt.close()


def main():
    parser = argparse.ArgumentParser(
        description='Compare PyTorch MLP performance with and without batch normalization'
    )
    parser.add_argument(
        '--no_bn_json',
        default='plots/pytorch_training_metrics.json',
        type=str,
        help='Path to JSON file for model without batch normalization'
    )
    parser.add_argument(
        '--with_bn_json',
        default='plots/pytorch_batch_norm_training_metrics.json',
        type=str,
        help='Path to JSON file for model with batch normalization'
    )
    parser.add_argument(
        '--output_plot',
        default='plots/batch_norm_comparison.png',
        type=str,
        help='Path to save comparison plot'
    )
    parser.add_argument(
        '--no_plot',
        action='store_true',
        help='Skip generating the comparison plot'
    )
    
    args = parser.parse_args()
    
    # Check if files exist
    if not os.path.exists(args.no_bn_json):
        print(f"Error: File not found: {args.no_bn_json}")
        print("Please run: python assignment1/train_mlp_pytorch.py")
        return
    
    if not os.path.exists(args.with_bn_json):
        print(f"Error: File not found: {args.with_bn_json}")
        print("Please run: python assignment1/train_mlp_pytorch.py --use_batch_norm")
        return
    
    # Read metrics from both JSON files
    metrics_no_bn = read_metrics_json(args.no_bn_json)
    metrics_with_bn = read_metrics_json(args.with_bn_json)
    
    # Print comparison table
    print_comparison_table(metrics_no_bn, metrics_with_bn)
    
    # Generate comparison plot
    if not args.no_plot:
        plot_comparison(metrics_no_bn, metrics_with_bn, save_path=args.output_plot)


if __name__ == '__main__':
    main()
